# SLAM-seq rotation project
*Austin Szatrowski, based on a SLAMseq analysis pipeline by Jesse Lehman, Pai Lab @ UMass Med*

## envs:
* `snakemake` is clean snakemake with the slurm execution plugin
* `slamseq_v1` is all (I think) the dependencies for Jesse's SLAM-seq pipeline
* `slamseq_fastp` is all the dependencies plus fastp
* `slamseq_v2` is all the dependencies for Jesse's SLAM-seq pipeline with kallisto 0.50.1 and multiqc
    * kallisto 0.51 encounters a known issue with indexes generated by previous versions ([kallisto:Issue #474](https://github.com/pachterlab/kallisto/issues/474))
    * major packages:
        * `snakemake`
            * `snakemake-executor-plugin-slurm`
            * `snakemake-storage-plugin-http`
        * `fastqc`
        * `fastp`
        * `hisat-3n`
        * `kallisto=0.50.1`
        * `samtools`
        * `multiqc`
        * `openjdk`
        * `fastqc`

## Folders
* `.snakemake`: under-the-hood metadata for DAG creation, plus execution (`log/`) and rule (`slurm_logs/`) log files
* `data`: symlinks to raw `.fastq` data in Hannah's personal folder, plus all intermediate outputs and space for `samtools` temp files. Anything that is too large to be part of a GitHub repo, not human-readable, or isn't an interesting result goes in here
* `outputs`: results, metadata, and QC summary folders. Of note, a _summary_ of the fastp checks go here, but individual reports go in `data`.

## Pipeline
* `setup.sh` is a setup file (run before anything else) that loads the correct python version and conda environment for snakemake, its plugins (slurm executor and http) and all the packages.

### Global inputs
* `*.fastq.gz` compressed sequencing files
* `ref_genome_assembly` a `.fa` reference genome file against which to align. I have used the Barreiro shared hg38 one.

### Outputs
* Read counts (?) this will be a journey of discovery

### Rules

#### `process_fastp`
* Pulls in each sequencing file (R1 and R2 separately), and runs `fastp`, which **includes adapter trimming**
* Output: trimmed fastq sequence files, `html` report and `json` machine-readable metadata
    * saved in `data/trimmed/`

#### `build_hisat3n_index`
* Builds a `hisat-3n` index fileset from a reference `.fa` genome file
* I used the one in Barreiro lab's shared reference directory, seemed to work fine
* Inserts T>C and complementary G>A substitutions in the genome to match the SLAMseq substitutions
* Output: 16 total files
    * `data/hisat3n_indexes/hg38.3n.CT.[1-8].ht2`
    * `data/hisat3n_indexes/hg38.3n.GA.[1-8].ht2`

#### `align_hisat3n`
* Align `data/trimmed/*_R[n]_001.fastq` read files to hg38 using the hg38 hisat-3n reference fileset
* Input: PAIRS of `data/trimmed/*_R[n]_001.fastq` files, since these represent the forward and reversed paired-end adapters used in the same sample
* Output: 
    * `aligned_sam` files, but these are wrapped in `temp()` which **will delete them after all dependent rules (i.e., those that call them as input) have been executed.**
        * that means that once `sam_to_bam` completes for each file/wildcard, the corresponding `.sam` file will be deleted 

#### `sam_to_bam`
* Does what it says on the tin—converts `.sam` files from the previous step to `.bam`.
* Filters out multi-mapped reads (field 260)
* Generates lots of temp files to store data out-of-memory, but assuming successful execution these should be cleaned up
    * I believe they persist if execution fails; unclear whether a restart can make use of them or just builds a new set
* `.sam` files are then discarded because of `temp()` in previous rule

#### `wget_kallisto_index`
* Downloads a pre-built hg38 kallisto index in `.tar.xz` format from Pachter Lab's Github storage
#### `decompress_kallisto_index`
* Decompresses the index tarball
#### `kallisto_quant`
* Runs [kallisto](https://pachterlab.github.io/kallisto/) transcript quantification using their pseudoalignment algorithm
* Returns a folder per `{sample_id}` containing `abundance.tsv` with transcript counts by ENST, `abundance.h5` (still not entirely sure what that is) and run metadata in `run_info.json`.
* stdout is stored in a log file at `logs/{sample_id}_kallisto.log`.
    * Of note, `multiqc` reads the log file for QC information, not `run_info.json`, which is dumb, especially because it doesn't read the log file correctly anyway (see below). Maybe there's a way to fix this.
#### `generate_tagvalues`
* `samtools view` counting requires string matching (per JL, it seems like there ought to be a better way), so this generates a `.txt` file containing the strings "2", "3", ..., "300" so it can call nascent transcripts.
#### `count_nascent_transcripts`
* Uses `samtools view` to read the `Yf:i:<str>` tag at the end of each transcript in `{sample_id}_aligned.bam`
* `Yf:i:<str>` contains the number of specified (T>C) substitutions present in the transcript, as determined by `hisat-3n`.
* If `<str>` appears in `tagvalues.txt` (from above), meaning the transcript contains ≥2 T>C substitutions, then that transcript is called as nascent
    * Per JL, there are slightly more careful ways to do this involving corrections for true SNPs and incomplete 4sU conversion, but this is fine for now.
#### `multiqc`
* Reads `logs/{sample_id}_kallisto.log` and `data/fastp_reports/{sample_id}.json` to generate summary information.
* kallisto runs in paired-end mode (R1 and R2 together) but for some reason `multiqc` only recognizes the `*_R1_001` filename in the log file, so it generates a separate entry. When reading **General Statistics** and the kallisto summary, assume the `_R1_001` data applies to the pair to which it belongs.

### Rulegraph:
![pipeline rulegraph](outputs/rulegraph_dag/rulegraph.png)